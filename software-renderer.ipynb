{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(points, screen):\n",
    "    bbmin = np.floor(np.min(points, 0)).astype('int')\n",
    "    bbmax = np.ceil(np.max(points, 0)).astype('int')\n",
    "    bbmin = np.clip(bbmin, [0, 0], [screen.shape[0] - 1, screen.shape[1] - 1])\n",
    "    bbmax = np.clip(bbmax, [0, 0], [screen.shape[0] - 1, screen.shape[1] - 1])    \n",
    "    return bbmin, bbmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfacing(tri_points):\n",
    "    # Check derminant (aka 2d cross product) of a triangle sector\n",
    "    M = np.concatenate(([tri_points[1] - tri_points[0]], [tri_points[2] - tri_points[0]]))\n",
    "    return np.linalg.det(M) < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_triangle(p, tri_points):\n",
    "    for i in range(3):\n",
    "        # Compute inward-pointing 2d normal of edge\n",
    "        edge = tri_points[(i + 1) % 3] - tri_points[i]\n",
    "        n = np.array([-edge[1], edge[0]])\n",
    "        \n",
    "        # The point is inside iff it lies on the correct side of all edges\n",
    "        if np.dot(n, p - tri_points[i]) < 0:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dehomogenize(V):\n",
    "    return V[:, 0:-1] / np.array([V[:, -1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_matrix(cam_pos, view_dir):\n",
    "    \n",
    "    world_up = np.array([0, 1, 0])\n",
    "    d = normalize(np.copy(view_dir))\n",
    "    right = normalize(np.cross(view_dir, world_up))\n",
    "    cam_up = normalize(np.cross(right, view_dir))\n",
    "    \n",
    "    # Assemble look-at matrix\n",
    "    T = np.identity(4)\n",
    "    T[0:3, 3] = -cam_pos\n",
    "    \n",
    "    R = np.identity(4)\n",
    "    R[0:3, 0] = right\n",
    "    R[0:3, 1] = cam_up\n",
    "    R[0:3, 2] = -d\n",
    "    \n",
    "    return np.matmul(R, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_matrix(fov_deg, near, far, screen):\n",
    "    # aka frustum transform\n",
    "    \n",
    "    fov_rad = fov_deg * np.pi / 180.\n",
    "    aspect_ratio = screen.shape[0] / screen.shape[1] # width/height\n",
    "    \n",
    "    top = near * np.tan(fov_rad / 2.)\n",
    "    bottom = -top\n",
    "    left = bottom * aspect_ratio\n",
    "    right = top * aspect_ratio\n",
    "    \n",
    "    # Assemble projection matrx\n",
    "    P = np.zeros((4, 4))\n",
    "    P[0, 0] = 2. * near / (right - left)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 1] = 2. * near / (top - bottom)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[2, 2] = -(far + near) / (far - near)\n",
    "    P[2, 3] = -2. * far * near / (far - near)\n",
    "    P[3, 2] = -1.\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertex_shader(V, N, MV, P):\n",
    "    # Switch to 4d homogeneous coordinates\n",
    "    V_hom = np.append(V, np.ones((V.shape[0], 1)), axis=1)\n",
    "    \n",
    "    # Compute vertex positions in camera space\n",
    "    # (multiplication from right because our vertices are row vectors)\n",
    "    V_cam = np.matmul(V_hom, MV.T)\n",
    "\n",
    "    # Compute normals in camera space\n",
    "    normal_transform = np.linalg.inv(MV[0:3, 0:3]).T\n",
    "    N_cam = np.matmul(N, normal_transform.T)\n",
    "    \n",
    "    # Compute vertex positions in normalized device coordinates\n",
    "    V_ndc = dehomogenize(np.matmul(V_cam, P.T))\n",
    "\n",
    "    V_cam = dehomogenize(V_cam)    \n",
    "    return V_cam, N_cam, V_ndc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize(V, T, screen):\n",
    "    # Pineda algorithm\n",
    "    fragments = []\n",
    "    \n",
    "    for t in T:\n",
    "        # V[t] is ...\n",
    "        # TODO\n",
    "        \n",
    "        # TODO: Activate backface culling again\n",
    "        #if backfacing(V[t]):\n",
    "        #    continue\n",
    "        \n",
    "        tri_points = V[t][:, 0:2]\n",
    "        \n",
    "        # Compute bounding box\n",
    "        bbmin, bbmax = bounding_box(tri_points, screen)\n",
    "        \n",
    "        # Check fragments within bounding box\n",
    "        for x in range(bbmin[0], bbmax[0] + 1):\n",
    "            for y in range(bbmin[1], bbmax[1] + 1):\n",
    "                if point_in_triangle([x, y], tri_points):\n",
    "                    fragments.append([x, y])\n",
    "    \n",
    "    return fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_shader(fragments, screen):\n",
    "    for x, y in fragments:\n",
    "        screen[x, y] = [255, 255, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(V, T, cam_pos, screen):\n",
    "    # Clear screen\n",
    "    screen[:] = np.array([64, 64, 64], dtype=np.uint8)\n",
    "    \n",
    "    # Compute normals\n",
    "    N = np.tile(np.array([0, 0, 1]), (V.shape[0], 1))\n",
    "    \n",
    "    # Get model_view and projection matrix\n",
    "    MV = view_matrix(cam_pos=cam_pos, view_dir=-cam_pos)\n",
    "    P = projection_matrix(fov_deg=90, near=0.01, far=100., screen=screen)\n",
    "    \n",
    "    # Transform vertices\n",
    "    V_cam, N_cam, V_ndc = vertex_shader(V, N, MV, P)\n",
    "    \n",
    "    # TODO: viewport transform?\n",
    "    print(\"V_cam\\n\", V_cam)\n",
    "    print(\"V_ndc\\n\", V_ndc)\n",
    "    \n",
    "    # Viewport transormation\n",
    "    w, h, _ = screen.shape\n",
    "    V_screen = V_ndc[:, 0:2] * np.array([w / 2., -h / 2.]) + np.array([w / 2., h / 2.])\n",
    "    \n",
    "    print(V_screen)\n",
    "    \n",
    "    # Generate list of fragments\n",
    "    fragments = rasterize(V_screen, T, screen)\n",
    "    \n",
    "    # Compute pixel colors\n",
    "    screen = fragment_shader(fragments, screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Init screen\n",
    "    height = 280\n",
    "    width = height * 16 // 9\n",
    "    screen = np.zeros((width, height, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Init scene\n",
    "    cam_pos = np.array([0, 0.5, 2])\n",
    "    \n",
    "    # TODO: Start with homogeneous coordinates right away?\n",
    "    \n",
    "    # Load mesh\n",
    "    V = np.array([[-0.8, -0.6, 0], [0.8, -0.6, 0], [0, 0.8, 0], [1, 0.5, 0], [0.5, 1, 0]], dtype=np.float)\n",
    "    T = np.array([[0, 1, 2], [2, 4, 3]], dtype=np.int)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    render(V, T, cam_pos, screen)\n",
    "\n",
    "    seconds = time.time() - start\n",
    "    print(\"Render took %f seconds.\" % seconds)\n",
    "\n",
    "    return screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_cam\n",
      " [[-0.8        -1.552228   -1.67349581]\n",
      " [ 0.8        -1.552228   -1.67349581]\n",
      " [ 0.         -0.1940285  -2.01304569]\n",
      " [ 1.         -0.48507125 -1.940285  ]\n",
      " [ 0.5         0.         -2.06155281]]\n",
      "V_ndc\n",
      " [[-0.269319   -0.92753623  0.98824779]\n",
      " [ 0.269319   -0.92753623  0.98824779]\n",
      " [ 0.         -0.09638554  0.99026383]\n",
      " [ 0.29035955 -0.25        0.98989123]\n",
      " [ 0.13663979  0.          0.99049762]]\n",
      "[[181.57422753 269.85507246]\n",
      " [315.42577247 269.85507246]\n",
      " [248.5        153.4939759 ]\n",
      " [320.65434845 175.        ]\n",
      " [282.45498751 140.        ]]\n",
      "Render took 0.177187 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAEYCAIAAADDG1hgAAAFLklEQVR4nO3dO3JbVxRFQUnlgd0zcnloDqyCUSpaBMn3AdbrjhDds6MFRuD3tdY3ABJ+nD0AgM1oOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkDHX2cPgIKfP/++fZ5ZJ62Ab9/XWmdvgBd2X/ObmXXsCvhF0+Ez3kz5vZm1/wr4nabDx7xb85uZtdsKeJumw0MeT/m9mbXpCniHpsM7PlfzezPryyvgIZoOb/t6yu/NrA1fg/+j6fC7bWt+M7P2eBbuaTr8slPK782svU9wcZoOR9T8ZmYddosL0nSu68iU35tZp9zlCjSdKzqr5jcz69wBVGk6F3J6yu/NrJMXUOR3GbmQmXXygjtP9QVDhr/TuagnSerMOnkBLZrO1Z0e95l17gBKNB3+c2LfZ9ZZpynRdHjDKXGfWccfJUbT4U8OjvvMOvIcPZoOjzqm7zPrgCtUaTp82N5xn1m7vk+YpsOX+BFHnoqmwzY2j/vM2vZBrkDTYWMbxn1mbfUUF6HpsCP/946DaToc4Stxn1kbraBP0+FQn4v7zNp0BVmaDqf5aN9n1g4rSNF0ON/jcZ9Zu62gQNPhiTwS95m18wpemKbDk/pD32fWUSt4MZoOz+7NuM+sY1fwGjQdXsZvcZ9ZZ6zgqWk6vKR/+z6zTl3B09F0gI4fZw8AYDOaDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtCh6QAdmg7QoekAHZoO0KHpAB2aDtDxD8pJgZHtRGzkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=497x280 at 0x10ABCD6D8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.transpose(test(), (1, 0, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

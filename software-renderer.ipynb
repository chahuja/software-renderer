{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_normals(V, T):\n",
    "    N = np.zeros((T.shape[0], 3))\n",
    "    for i in range(T.shape[0]):\n",
    "        ps = V[T[i]] # Three triangle vertex positions as row vectors\n",
    "        N[i] = normalize(np.cross(ps[1] - ps[0], ps[2] - ps[0]))\n",
    "        \n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(points, screen):\n",
    "    bbmin = np.floor(np.min(points, 0)).astype('int')\n",
    "    bbmax = np.ceil(np.max(points, 0)).astype('int')\n",
    "    bbmin = np.clip(bbmin, [0, 0], [screen.shape[0] - 1, screen.shape[1] - 1])\n",
    "    bbmax = np.clip(bbmax, [0, 0], [screen.shape[0] - 1, screen.shape[1] - 1])    \n",
    "    return bbmin, bbmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfacing(tri_points):\n",
    "    # Check derminant (aka 2d cross product) of a triangle sector\n",
    "    M = np.concatenate(([tri_points[1] - tri_points[0]], [tri_points[2] - tri_points[0]]))\n",
    "    return np.linalg.det(M) > 0 # Screen space is left-handed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_triangle(p, tri_points):\n",
    "    for i in range(3):\n",
    "        # Compute inward-pointing 2d normal of edge\n",
    "        edge = tri_points[(i + 1) % 3] - tri_points[i]\n",
    "        n = np.array([-edge[1], edge[0]])\n",
    "        \n",
    "        # The point is inside iff it lies on the correct side of all edges\n",
    "        if np.dot(n, p - tri_points[i]) > 0: # Screen space is left-handed\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dehomogenize(V):\n",
    "    return V[:, 0:-1] / np.array([V[:, -1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_matrix(cam_pos, view_dir):\n",
    "    \n",
    "    world_up = np.array([0, 1, 0])\n",
    "    d = normalize(np.copy(view_dir))\n",
    "    right = normalize(np.cross(view_dir, world_up))\n",
    "    cam_up = normalize(np.cross(right, view_dir))\n",
    "    \n",
    "    # Assemble look-at matrix\n",
    "    T = np.identity(4)\n",
    "    T[0:3, 3] = -cam_pos\n",
    "    \n",
    "    R = np.identity(4)\n",
    "    R[0:3, 0] = right\n",
    "    R[0:3, 1] = cam_up\n",
    "    R[0:3, 2] = -d\n",
    "    \n",
    "    return np.matmul(R.T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_matrix(fov_deg, near, far, screen):\n",
    "    # aka frustum transform   \n",
    "    fov_rad = fov_deg * np.pi / 180.\n",
    "    aspect_ratio = screen.shape[0] / screen.shape[1] # width/height\n",
    "    \n",
    "    top = near * np.tan(fov_rad / 2.)\n",
    "    bottom = -top\n",
    "    left = bottom * aspect_ratio\n",
    "    right = top * aspect_ratio\n",
    "    \n",
    "    # Assemble projection matrx\n",
    "    P = np.zeros((4, 4))\n",
    "    P[0, 0] = 2. * near / (right - left)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 1] = 2. * near / (top - bottom)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[2, 2] = -(far + near) / (far - near)\n",
    "    P[2, 3] = -2. * far * near / (far - near)\n",
    "    P[3, 2] = -1.\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertex_shader(V, N, MV, P):\n",
    "    # Switch to 4d homogeneous coordinates\n",
    "    V_hom = np.append(V, np.ones((V.shape[0], 1)), axis=1)\n",
    "    \n",
    "    # Compute vertex positions in camera space\n",
    "    # (multiplication from right because our vertices are row vectors)\n",
    "    V_cam = np.matmul(V_hom, MV.T)\n",
    "\n",
    "    # Compute normals in camera space\n",
    "    normal_transform = np.linalg.inv(MV[0:3, 0:3]).T\n",
    "    N_cam = np.matmul(N, normal_transform.T)\n",
    "    \n",
    "    # Compute vertex positions in normalized device coordinates\n",
    "    V_ndc = dehomogenize(np.matmul(V_cam, P.T))\n",
    "    \n",
    "    V_cam = dehomogenize(V_cam)    \n",
    "    return V_cam, N_cam, V_ndc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shade_fragment(x, y, p_cam, n_cam, screen):\n",
    "    ambient = np.array([0.2, 0.2, 0.2])\n",
    "    neg_cam_dir = np.array([0, 0, 1])\n",
    "    diffuse_color = np.array([255, 0, 128])\n",
    "    diffuse = diffuse_color * np.dot(n_cam, neg_cam_dir)\n",
    "    \n",
    "    screen[x, y] =  * np.dot(n_cam, )) + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_and_shade(V_screen, T, N, screen):\n",
    "    # Pineda algorithm\n",
    "    #fragments = []\n",
    "    \n",
    "    for i, t in enumerate(T):\n",
    "        # Get screen space positions of triangle vertices (3x2 matrix)\n",
    "        tri_points = V_screen[t]\n",
    "        \n",
    "        # TODO: Activate backface culling again\n",
    "        if backfacing(tri_points):\n",
    "            continue\n",
    "        \n",
    "        # Compute bounding box\n",
    "        bbmin, bbmax = bounding_box(tri_points, screen)\n",
    "        \n",
    "        # Check fragments within bounding box\n",
    "        for x in range(bbmin[0], bbmax[0] + 1):\n",
    "            for y in range(bbmin[1], bbmax[1] + 1):\n",
    "                if point_in_triangle([x, y], tri_points):\n",
    "                    shade_fragment(x, y, None, N[i], screen)\n",
    "                    #fragments.append([x, y])\n",
    "    \n",
    "    #return fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(V, T, N, cam_pos, screen):\n",
    "    # Clear screen\n",
    "    screen[:] = np.array([64, 64, 64], dtype=np.uint8)\n",
    "    \n",
    "    # Get model_view and projection matrix\n",
    "    MV = view_matrix(cam_pos=cam_pos, view_dir=-cam_pos)\n",
    "    P = projection_matrix(fov_deg=90, near=0.01, far=100., screen=screen)\n",
    "    \n",
    "    # Transform vertices\n",
    "    V_cam, N_cam, V_ndc = vertex_shader(V, N, MV, P)\n",
    "    \n",
    "    # Viewport transormation\n",
    "    w, h, _ = screen.shape\n",
    "    V_screen = V_ndc[:, 0:2] * np.array([w / 2., -h / 2.]) + np.array([w / 2., h / 2.])\n",
    "    \n",
    "    # Rasterize and immediately shade fragments\n",
    "    rasterize_and_shade(V_screen, T, N_cam, screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Init screen\n",
    "    height = 280\n",
    "    width = height * 16 // 9\n",
    "    screen = np.zeros((width, height, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Init scene\n",
    "    cam_pos = np.array([2, 3, 4.])\n",
    "    \n",
    "    # Load mesh\n",
    "    V = np.array([[-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1], [1, -1, -1], [1, 1, -1], [-1, 1, -1]], dtype=np.float)\n",
    "    T = np.array([[0, 1, 2], [2, 3, 0], [1, 4, 5], [5, 2, 1], [2, 5, 6], [6, 3, 2]], dtype=np.int)\n",
    "\n",
    "    # Compute per-triangle normals\n",
    "    N = triangle_normals(V, T)\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    render(V, T, N, cam_pos, screen)\n",
    "\n",
    "    seconds = time.time() - start\n",
    "    print(\"Render took %f seconds.\" % seconds)\n",
    "\n",
    "    return screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Render took 0.246154 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=497x280 at 0x10352BE48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.transpose(test(), (1, 0, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

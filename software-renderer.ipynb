{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(points, screen):\n",
    "    bbmin = np.floor(np.min(points, 0)).astype('int')\n",
    "    bbmax = np.ceil(np.max(points, 0)).astype('int')\n",
    "    bbmin = np.clip(bbmin, [0, 0], [screen.shape[0] - 1, screen.shape[1] - 1])\n",
    "    bbmax = np.clip(bbmax, [0, 0], [screen.shape[0] - 1, screen.shape[1] - 1])    \n",
    "    return bbmin, bbmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfacing(tri_points):\n",
    "    # Check derminant (aka 2d cross product) of a triangle sector\n",
    "    M = np.concatenate(([tri_points[1] - tri_points[0]], [tri_points[2] - tri_points[0]]))\n",
    "    return np.linalg.det(M) > 0 # Screen space is left-handed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_triangle(p, tri_points):\n",
    "    for i in range(3):\n",
    "        # Compute inward-pointing 2d normal of edge\n",
    "        edge = tri_points[(i + 1) % 3] - tri_points[i]\n",
    "        n = np.array([-edge[1], edge[0]])\n",
    "        \n",
    "        # The point is inside iff it lies on the correct side of all edges\n",
    "        if np.dot(n, p - tri_points[i]) > 0: # Screen space is left-handed\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dehomogenize(V):\n",
    "    return V[:, 0:-1] / np.array([V[:, -1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_matrix(cam_pos, view_dir):\n",
    "    \n",
    "    world_up = np.array([0, 1, 0])\n",
    "    d = normalize(np.copy(view_dir))\n",
    "    right = normalize(np.cross(view_dir, world_up))\n",
    "    cam_up = normalize(np.cross(right, view_dir))\n",
    "    \n",
    "    # Assemble look-at matrix\n",
    "    T = np.identity(4)\n",
    "    T[0:3, 3] = -cam_pos\n",
    "    \n",
    "    R = np.identity(4)\n",
    "    R[0:3, 0] = right\n",
    "    R[0:3, 1] = cam_up\n",
    "    R[0:3, 2] = -d\n",
    "    \n",
    "    return np.matmul(R.T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_matrix(fov_deg, near, far, screen):\n",
    "    # aka frustum transform\n",
    "    \n",
    "    fov_rad = fov_deg * np.pi / 180.\n",
    "    aspect_ratio = screen.shape[0] / screen.shape[1] # width/height\n",
    "    \n",
    "    top = near * np.tan(fov_rad / 2.)\n",
    "    bottom = -top\n",
    "    left = bottom * aspect_ratio\n",
    "    right = top * aspect_ratio\n",
    "    \n",
    "    # Assemble projection matrx\n",
    "    P = np.zeros((4, 4))\n",
    "    P[0, 0] = 2. * near / (right - left)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 1] = 2. * near / (top - bottom)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[2, 2] = -(far + near) / (far - near)\n",
    "    P[2, 3] = -2. * far * near / (far - near)\n",
    "    P[3, 2] = -1.\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertex_shader(V, N, MV, P):\n",
    "    # Switch to 4d homogeneous coordinates\n",
    "    V_hom = np.append(V, np.ones((V.shape[0], 1)), axis=1)\n",
    "    \n",
    "    # Compute vertex positions in camera space\n",
    "    # (multiplication from right because our vertices are row vectors)\n",
    "    V_cam = np.matmul(V_hom, MV.T)\n",
    "\n",
    "    # Compute normals in camera space\n",
    "    normal_transform = np.linalg.inv(MV[0:3, 0:3]).T\n",
    "    N_cam = np.matmul(N, normal_transform.T)\n",
    "    \n",
    "    # Compute vertex positions in normalized device coordinates\n",
    "    V_ndc = dehomogenize(np.matmul(V_cam, P.T))\n",
    "    \n",
    "    V_cam = dehomogenize(V_cam)    \n",
    "    return V_cam, N_cam, V_ndc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize(V_screen, T, screen):\n",
    "    # Pineda algorithm\n",
    "    fragments = []\n",
    "    \n",
    "    for t in T:\n",
    "        # Get screen space positions of triangle vertices (3x2 matrix)\n",
    "        tri_points = V_screen[t]\n",
    "        \n",
    "        # TODO: Activate backface culling again\n",
    "        if backfacing(tri_points):\n",
    "            continue\n",
    "        \n",
    "        # Compute bounding box\n",
    "        bbmin, bbmax = bounding_box(tri_points, screen)\n",
    "        \n",
    "        # Check fragments within bounding box\n",
    "        for x in range(bbmin[0], bbmax[0] + 1):\n",
    "            for y in range(bbmin[1], bbmax[1] + 1):\n",
    "                if point_in_triangle([x, y], tri_points):\n",
    "                    fragments.append([x, y])\n",
    "    \n",
    "    return fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_shader(fragments, screen):\n",
    "    for x, y in fragments:\n",
    "        screen[x, y] = [255, 255, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(V, T, cam_pos, screen):\n",
    "    # Clear screen\n",
    "    screen[:] = np.array([64, 64, 64], dtype=np.uint8)\n",
    "    \n",
    "    # Compute normals\n",
    "    N = np.tile(np.array([0, 0, 1]), (V.shape[0], 1))\n",
    "    \n",
    "    # Get model_view and projection matrix\n",
    "    MV = view_matrix(cam_pos=cam_pos, view_dir=-cam_pos)\n",
    "    P = projection_matrix(fov_deg=90, near=0.01, far=100., screen=screen)\n",
    "    \n",
    "    # Transform vertices\n",
    "    V_cam, N_cam, V_ndc = vertex_shader(V, N, MV, P)\n",
    "    \n",
    "    # Viewport transormation\n",
    "    # Invert y\n",
    "    w, h, _ = screen.shape\n",
    "    V_screen = V_ndc[:, 0:2] * np.array([w / 2., -h / 2.]) + np.array([w / 2., h / 2.])\n",
    "    \n",
    "    # Generate list of fragments\n",
    "    fragments = rasterize(V_screen, T, screen)\n",
    "    \n",
    "    # Compute pixel colors\n",
    "    screen = fragment_shader(fragments, screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Init screen\n",
    "    height = 280\n",
    "    width = height * 16 // 9\n",
    "    screen = np.zeros((width, height, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Init scene\n",
    "    cam_pos = np.array([2., 2, 4.])\n",
    "    \n",
    "    # Load mesh\n",
    "    V = np.array([[-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1], [1, -1, -1], [1, 1, -1]], dtype=np.float)\n",
    "    T = np.array([[0, 1, 2], [2, 3, 0], [1, 4, 5], [5, 2, 1]], dtype=np.int)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    render(V, T, cam_pos, screen)\n",
    "\n",
    "    seconds = time.time() - start\n",
    "    print(\"Render took %f seconds.\" % seconds)\n",
    "\n",
    "    return screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Render took 0.225474 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAEYCAIAAADDG1hgAAAFbElEQVR4nO3dOW7kSBRFUVWjFhZ/5aqltZHouQYgm8lgXp5j0aKenIsPGtKXtdYHAAm/7R4AwGE0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HaBD0wE6NB2gQ9MBOjQdoEPTATo0HV7i8/Pb7gnckabD8QSdXb7uHgApas5e7nQ4jKCznabDMQSdK9B0OICgcxG+p/Na343dzDp3xQupOZei6WyQCf1Pgj6zzloBf9F0ruLtQu9C54K+rLV2byDu8PbNrGNf+IRf/lIz6/Ur4N/c6byfvRe985wr03Qizgm9oHNxmk7ZsaEXdK5P07md50Iv6LwFTYePj1+FXtB5F5oOPyTlvB1/GwCON7M2L+CuNJ2Xm1mbF8BtaDpAh6YDdGg6QIemA3RoOkCHpgN0aDpnmFmbF8A9aDocbGZtXsCNaTpAh6YDdGg6QIemA3RoOkCHpnOSmbV5AdyApgN0aDpAh6bDkWbW5gXcm6YDdGg6QIemA3RoOkCHpnOembV5AdRpOkCHpgN0aDpAh6bDYWbW5gXcnqYDdGg6QIemc6qZtXkBpGk6QIemA3RoOhxjZm1eAJoOUKLpcICZtXkBfHx8aDpAiaZztpm1ecHRZtbmBfAHTQfo0HT4X2bW5gXwN5oOz5tZmxfAP2k6QIemw5Nm1uYF8B+aDtCh6fCMmbV5AXyPprPBzNq8AKK+rLV2b+C+Pj+/7Z7wjJm1eQH8wNfdA7i1mfV4eNO4w9W407mQtyj7zNq8AH7Mnc6FzKzHw1vEHS7Inc6lXS3uM2vzAvgpTec9XCHuM2vzAvgV3154DzPr8XCFuMNludN5VyfHfWad+ePgOe503tXMejy43OFP7nQiXlr2mfW6l8OB3OlEzKzHg7OdO3Onk3VU3GfWIe+BE7jTyZpZjweXO/fhTudGnoj7zDp6BbyQO50bmVmPB5c7Ve50bu3ncZ9Zp6yAw2g6fL/sM+vcFXAA317ANxk63OkAHf4fKUCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QIemA3RoOkCHpgN0aDpAh6YDdGg6QMfvx7SQEG0fs24AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=497x280 at 0x10F47EBA8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.transpose(test(), (1, 0, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
